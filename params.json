{"name":"Sea-final-project","tagline":"","body":"# SEA-final-project\r\nBuilding up movie seach engine plus customized recommendation system\r\n\r\n# /constants\r\n\r\nCould be empty, but since Rotten Tomato API has usage limit per day, we suggest not to run the crawler everytime. <br>\r\n[After crawler](https://www.dropbox.com/sh/xalfjcriwi454jk/AAAMobUvhL6ACebRardmkVDla?dl=0)\r\n\r\nWith files in following link, you can fire up the server immediately <br>\r\n[Ready to serve](https://www.dropbox.com/sh/vln8xpvd6toerve/AAAg_GMUa_u12YbjVrUoCkyKa?dl=0)\r\n\r\nbackup <br>\r\n[google drive](https://drive.google.com/folderview?id=0BzG5zLRRrgKwfkFPVHE5ZUZ2WGVZM28wUXZqUzU5WmhuZ3ZFdURTMzNYNzJNeVN2T1dGWWM&usp=sharing)\r\n\r\n# Run \r\n\r\n## 0. Run crawler\r\n\r\n## 1. Split data into many partitions\r\n```\r\npython -m src.reformatter <# of partitions for review> <# of partitions for movie>\r\npython -m src.reformatter 4 5 \r\n```\r\n## 2. Call prework workers\r\n```\r\npython -m PreworkWorkers\r\n```\r\n## 3. Spin up fs system\r\n```\r\npython -m fsStart\r\n```\r\n## 4. Prepare data for servers\r\n```\r\npython -m PrepareFS\r\n\r\n# Note, the num of partitions should corresping to the num of backend works\r\n# Default: (NumSuperFront, NumMaster, NumMovie, NumReview, NumIdx, NumDoc)= (1, 3, 3, 3, 3, 3)\r\n```\r\n## 5. Start All the works\r\nGoal: 1. find ports, 2. fire up all servers\r\n```\r\npython ./StartAll.py\r\n```\r\n## 6. Fire up frontend\r\nNeed to install Google App Engine SDK first: https://cloud.google.com/sdk/#Quick_Start\r\n```\r\ndev_appserver.py --host=localhost --port=8080 frontend\r\n# then the frontend server runs at port 8080\r\n```\r\n## 7. Try it (in browser)\r\nfollowing the above example\r\n```\r\nhttp://127.0.0.1:8080/\r\n```\r\n\r\n#Structure:\r\nThe structure of fired-uped HTTP servers are:\r\n```\r\n                        --> classifier_front(?)   --> ?\r\nUser --> SuperFront     --> searchEng_front       --> searchEng_worker (inclusing IndexServer*3, and DocumentServer*3)\r\n                        --> recom_front           --> recom_worker (inclusing MovieServer*3, and ReviewServer*3)\r\n```\r\n#Recommendation System:\r\n###Goal: getting the user ID --> check user log to get review history --> check MovieServer to get similar critics --> check ReviewServer to get movies sorted by weighted rating\r\n###Stucture and Usage:\r\n```\r\nrecom_front --> MovieServer*3\r\n            --> ReviewServer*3\r\n\r\n#recom_front api: \r\n#http://linserv2.cims.nyu.edu:46829/recom?user=UserID (e.g. http://linserv2.cims.nyu.edu:46829/recom?user=d0aa6e9b-676b-428f-9758-65e7c09b38a4)\r\n\r\n#MovieServer api:\r\n# http://linserv2.cims.nyu.edu:46831/movie?movieID=MovieIDs (e.g. http://linserv2.cims.nyu.edu:46831/movie?movieID=770802394+770882996+12900+13217+11705+770876740+770710325+771362322+533693794+348462568)\r\n\r\n#ReviewServer api:\r\n#http://linserv2.cims.nyu.edu:46834/review?critics=CRITICS (e.g. http://linserv2.cims.nyu.edu:46834/review?critics=Emanuel_Levy+Roger_Ebert)\r\n```\r\n\r\nCurrent UserLog is created by:\r\n```\r\npython ./src/createFakeUserLog.py\r\n\r\n#So it will create 20 reviews per user with random scoring on random movie. Total for 50 users with unique ID created.  \r\n#saved at ../userLog/myUserBook\r\n```\r\n\r\n\r\n#TomatoCrawler\r\n##Goal: to fetch rotten tomato website and save the info properly\r\nNow we have:\r\n- 250 movie to search\r\n- 1718 movieIDs returned\r\n```python\r\n#If you like tomatoCrawler to save Movie_fs, Review_fs, and IDs_fs to file system\r\nfrom src import tomatoCrawler\r\ntomatoCrawler.main2FS()\r\n\r\n#Or! just ask tomatoCrawler to save Movie_dict, Review_fs, and IDs_fs to ./constants as pickle files\r\ntomatoCrawler.main2NormalDict()\r\n```\r\n\r\n\r\n#File System module Usage\r\n##Distributed dictionary object\r\n```python\r\nfrom fs import DisTable\r\n\r\n#Creating an object\r\na = DisTable()\r\n# or\r\nb = DisTable({ 1: 'a', 2: 'b', 3: 'c'})\r\n\r\n#Set a key-value pair\r\na[1] = 'a'\r\na[2] = 'b'\r\n#Get a value with key\r\na[1]\r\n#returns 'a'\r\n\r\n#Pop operation\r\na.pop(1)\r\n#returns 'a' and remove (1, 'a') from dictionary\r\n\r\n#hasKey operation\r\na.hasKey(2)\r\n#returns True\r\na.hasKey(1)\r\n#returns False\r\n\r\n#Length property\r\na.length\r\n#returns 1\r\n\r\n#Pretty print of dictionary\r\nprint a\r\n#1\r\n#   a\r\n'''\r\nkey1\r\n  value1\r\n  value2\r\n  ...\r\nkey2\r\n  value1\r\n  value2\r\n  ...\r\n'''\r\n```\r\n\r\n##Distributed List\r\n```python\r\nfrom fs import DisList\r\n\r\n#Creating an object\r\na = DisList()\r\n# or\r\nb = DisList([1, 2, 3, 4])\r\n\r\n#Append/Extend a value into list\r\na.append(1)\r\na.append(2)\r\na.extend(3)\r\na.extend(4)\r\n\r\n#Get a value given position\r\na[0]\r\n#returns 1\r\na[1]\r\n#returns 2\r\n\r\n#Update value to given position\r\na[1] = 3\r\nprint a\r\n#[ 1 3 3 4 ]\r\n\r\n#Remove value from list\r\na.remove(1)\r\nprint a\r\n#[ 3 3 4 ]\r\na.remove(3, globl=True)\r\nprint a\r\n#[ 4 ]\r\n\r\n#Pop operation\r\na.pop(1)\r\n#returns 'a' and remove (1, 'a') from dictionary\r\n\r\n#Length property\r\na.length\r\n#returns 1\r\n```\r\n","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}